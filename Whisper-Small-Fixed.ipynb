{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21125ed1",
   "metadata": {},
   "source": [
    "# System Dependencies and Additional Packages\n",
    "This cell updates the system packages and installs ffmpeg for audio processing, along with additional Python packages including datasets, transformers, torchaudio, evaluate, jiwer, torchcodec, and tensorboard. It also upgrades transformers and accelerate to their latest versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea804f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \n",
      "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 108 not upgraded.\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.2)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: torch==2.8.0.dev20250319 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch==2.8.0.dev20250319->torchaudio) (77.0.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.0)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.14.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.75.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.9)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard) (11.0.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (6.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.8.0.dev20250319->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.0.0->accelerate) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!apt-get update -y\n",
    "!apt-get install -y ffmpeg\n",
    "!pip install datasets transformers torchaudio evaluate jiwer torchcodec tensorboard scikit-learn accelerate\n",
    "!pip install --upgrade transformers accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f2329",
   "metadata": {},
   "source": [
    "# Imports and Configuration Setup\n",
    "This cell imports all necessary libraries for data processing, audio handling, and machine learning. It sets up environment variables to disable tokenizers parallelism warnings and defines configuration parameters including the number of processors and sampling rate. It also creates the base directory for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548e6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Features, Value, Audio\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import evaluate\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Set environment variable to disable tokenizers parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Konfigurasi umum\n",
    "num_proc = os.cpu_count()\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Direktori kerja\n",
    "base_dir = Path(\"/workspace/data/audio_train/librivox-indonesia\")\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae1adf",
   "metadata": {},
   "source": [
    "# Download Dataset Files\n",
    "This cell downloads the necessary dataset files from Hugging Face, including training and test audio archives, and their corresponding metadata CSV files compressed with gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26adca17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‚Äò/workspace/data/audio_train.tgz‚Äô already there; not retrieving.\n",
      "\n",
      "File ‚Äò/workspace/data/audio_test.tgz‚Äô already there; not retrieving.\n",
      "\n",
      "File ‚Äò/workspace/data/metadata_train.csv.gz‚Äô already there; not retrieving.\n",
      "\n",
      "File ‚Äò/workspace/data/metadata_test.csv.gz‚Äô already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/resolve/main/data/audio_train.tgz -P /workspace/data/\n",
    "!wget -nc https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/resolve/main/data/audio_test.tgz -P /workspace/data/\n",
    "!wget -nc https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/resolve/main/data/metadata_train.csv.gz -P /workspace/data/\n",
    "!wget -nc https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia/resolve/main/data/metadata_test.csv.gz -P /workspace/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8518",
   "metadata": {},
   "source": [
    "# Extract Audio Archives\n",
    "This cell extracts the downloaded tar.gz archives containing the training and test audio files to the specified directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrak audio\n",
    "for archive in [\"/workspace/data/audio_train.tgz\", \"/workspace/data/audio_test.tgz\"]:\n",
    "    with tarfile.open(archive, \"r:gz\") as tar:\n",
    "        tar.extractall(path=\"/workspace/data/audio_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76eae3",
   "metadata": {},
   "source": [
    "# Audio Format Conversion\n",
    "This cell converts all audio files from their original formats to WAV format with mono channel and 16kHz sampling rate using ffmpeg. It processes the files in parallel for efficiency and updates the metadata CSV to reflect the new file paths. The conversion ensures compatibility with the Whisper model's audio processing requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135044e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# --- Paths ---\n",
    "audio_base_path = \"/workspace/data/audio_train/librivox-indonesia\"\n",
    "output_base = os.path.join(audio_base_path, \"converted_wav\")\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# üìå Metadata asli\n",
    "metadata_path = \"/workspace/data/metadata_train.csv.gz\"\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# --- Worker function for parallel ffmpeg ---\n",
    "def convert_to_wav(rel_path):\n",
    "    if pd.isna(rel_path):\n",
    "        return None\n",
    "\n",
    "    src_path = os.path.join(audio_base_path, rel_path)\n",
    "    if not os.path.exists(src_path):\n",
    "        return None\n",
    "\n",
    "    out_rel_path = os.path.splitext(rel_path)[0] + \".wav\"\n",
    "    out_path = os.path.join(output_base, out_rel_path)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    # ‚úÖ Skip jika sudah ada\n",
    "    if os.path.exists(out_path):\n",
    "        return os.path.relpath(out_path, audio_base_path)\n",
    "\n",
    "    cmd = [\"ffmpeg\", \"-y\", \"-i\", src_path, \"-ac\", \"1\", \"-ar\", \"16000\", out_path]\n",
    "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    return os.path.relpath(out_path, audio_base_path)\n",
    "\n",
    "# --- Run parallel conversion ---\n",
    "new_paths = []\n",
    "with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = {executor.submit(convert_to_wav, rel_path): rel_path for rel_path in df[\"path\"].astype(str)}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Converting to WAV\"):\n",
    "        new_paths.append(future.result())\n",
    "\n",
    "# --- Update metadata ke versi WAV ---\n",
    "df[\"path\"] = new_paths\n",
    "new_meta_path = os.path.join(audio_base_path, \"metadata_train_wav.csv\")\n",
    "df.to_csv(new_meta_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Conversion done. Metadata saved: {new_meta_path}\")\n",
    "print(f\"üìÇ Converted audio saved under: {output_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7459b",
   "metadata": {},
   "source": [
    "# Cleanup Original Audio Files\n",
    "This cell removes the original MP3 files after conversion to WAV format to save disk space and avoid confusion between different audio formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8797d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Cleaning MP3 in /workspace/data/audio_train/librivox-indonesia ...\n",
      "‚úÖ Removed 7815 MP3 files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "def cleanup_mp3(split_dir):\n",
    "    print(f\"üóëÔ∏è Cleaning MP3 in {split_dir} ...\")\n",
    "    removed = 0\n",
    "    for mp3 in glob.glob(os.path.join(split_dir, \"**\", \"*.mp3\"), recursive=True):\n",
    "        try:\n",
    "            os.remove(mp3)\n",
    "            removed += 1\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"‚úÖ Removed {removed} MP3 files\")\n",
    "\n",
    "cleanup_mp3(audio_base_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27157f",
   "metadata": {},
   "source": [
    "# Dataset Preparation for Minangkabau Language\n",
    "This cell loads the converted metadata, filters the dataset to include only Minangkabau language samples, adds absolute file paths, and converts the pandas DataFrame to a Hugging Face Dataset object for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5408069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'converted_wav/train/sundanese/universal-declaration-of-human-rights/human_rights_un_sun_brc_0113.wav', 'language': 'min', 'reader': 3232, 'sentence': 'manusia sadonyo lahia ka dunia mambao hak hak dan kamardekaan mandasar nan samo dan indak dapek dipisahkan', 'full_path': '/workspace/data/audio_train/librivox-indonesia/converted_wav/train/sundanese/universal-declaration-of-human-rights/human_rights_un_sun_brc_0113.wav', '__index_level_0__': 140}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "audio_base_path = \"/workspace/data/audio_train/librivox-indonesia\"\n",
    "metadata_path = os.path.join(audio_base_path, \"metadata_train_wav.csv\")\n",
    "\n",
    "# Baca metadata & filter hanya Minangkabau\n",
    "df = pd.read_csv(metadata_path)\n",
    "df = df[df[\"language\"] == \"min\"]\n",
    "\n",
    "# Tambah absolute path\n",
    "df[\"full_path\"] = df[\"path\"].apply(lambda p: os.path.join(audio_base_path, p))\n",
    "\n",
    "# Convert ke HuggingFace Dataset\n",
    "ds_minang = Dataset.from_pandas(df)\n",
    "print(ds_minang[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c95ebc",
   "metadata": {},
   "source": [
    "# Load Whisper Model and Processor\n",
    "This cell loads the pre-trained OpenAI Whisper Small model and its processor from Hugging Face. The model is moved to GPU (CUDA) for faster training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90fc831-26ea-4b23-a928-5b8c66bb4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "model_name = \"openai/whisper-small\"\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Pastikan model ke GPU\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32daea07",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing and Training Setup\n",
    "This cell performs comprehensive setup for fine-tuning the Whisper model: loads the model and processor configured for Minangkabau language transcription, prepares the dataset by splitting into train/validation sets, applies preprocessing to convert audio waveforms to model inputs, and sets up the data collator for sequence-to-sequence training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe29fcf-6a22-4645-b205-366039c5c371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9d515cfb774d8c9a3d80eae9cb93d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d13386ad9164e7196baf4e06ff7388d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# --- Config ---\n",
    "audio_base_path = \"/workspace/data/audio_train/librivox-indonesia\"\n",
    "metadata_path = os.path.join(audio_base_path, \"metadata_train_wav.csv\")\n",
    "SAMPLING_RATE = 16000\n",
    "model_name = \"openai/whisper-small\"\n",
    "\n",
    "# --- Load model & processor ---\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"minangkabau\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move generation config parameters to avoid warnings\n",
    "model.generation_config.max_length = 448\n",
    "model.generation_config.suppress_tokens = [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362]\n",
    "model.generation_config.begin_suppress_tokens = [220, 50257]\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# --- STEP 1: Load metadata ---\n",
    "df = pd.read_csv(metadata_path)\n",
    "df[\"full_path\"] = df[\"path\"].apply(lambda p: os.path.join(audio_base_path, p))\n",
    "\n",
    "# Fokus hanya Minangkabau\n",
    "df = df[df[\"language\"] == \"min\"].reset_index(drop=True)\n",
    "\n",
    "# Split train/validation\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert ke HF Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "# --- STEP 2: Preprocessing function ---\n",
    "def prepare_dataset(batch):\n",
    "    # load audio\n",
    "    waveform, sr = torchaudio.load(batch[\"full_path\"])\n",
    "    if sr != SAMPLING_RATE:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, SAMPLING_RATE)\n",
    "    waveform = waveform.mean(dim=0)  # mono\n",
    "\n",
    "    # process\n",
    "    inputs = processor(\n",
    "        audio=waveform.numpy(),\n",
    "        sampling_rate=SAMPLING_RATE,\n",
    "        text=batch[\"sentence\"]\n",
    "    )\n",
    "    return {\n",
    "        \"input_features\": inputs[\"input_features\"][0],\n",
    "        \"labels\": inputs[\"labels\"]\n",
    "    }\n",
    "\n",
    "train_ds = train_ds.map(prepare_dataset)\n",
    "val_ds = val_ds.map(prepare_dataset)\n",
    "\n",
    "# --- STEP 3: Data Collator (fixed for tokenized labels) ---\n",
    "@torch.no_grad()\n",
    "def data_collator(features):\n",
    "    # Separate inputs and labels for clarity\n",
    "    input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "    labels = [feature[\"labels\"] for feature in features]\n",
    "\n",
    "    # Use feature extractor for audio inputs\n",
    "    batch = processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "    # Convert labels to tensors and pad them manually\n",
    "    # Labels are already tokenized, so we need to pad them as integers\n",
    "    max_length = max(len(label) for label in labels)\n",
    "    \n",
    "    padded_labels = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for label in labels:\n",
    "        # Pad with -100 (ignored in loss calculation)\n",
    "        padded_label = label + [-100] * (max_length - len(label))\n",
    "        attention_mask = [1] * len(label) + [0] * (max_length - len(label))\n",
    "        \n",
    "        padded_labels.append(padded_label)\n",
    "        attention_masks.append(attention_mask)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    labels_tensor = torch.tensor(padded_labels, dtype=torch.long)\n",
    "    attention_mask = torch.tensor(attention_masks, dtype=torch.long)\n",
    "    \n",
    "    # Replace padding tokens with -100 for loss calculation\n",
    "    labels_tensor = labels_tensor.masked_fill(attention_mask.ne(1), -100)\n",
    "\n",
    "    # Trim BOS token if present\n",
    "    if (labels_tensor[:, 0] == processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "        labels_tensor = labels_tensor[:, 1:]\n",
    "\n",
    "    batch[\"labels\"] = labels_tensor\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6f76f",
   "metadata": {},
   "source": [
    "# Training Arguments Configuration\n",
    "This cell configures the training arguments for the Seq2SeqTrainer, including batch sizes, evaluation and save intervals, mixed precision training (FP16), and TensorBoard logging. It removes deprecated arguments to ensure compatibility with the transformers library version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc1c6557-1c06-45ff-9e4e-543694860b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Trainer ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-minang-checkpoints\",\n",
    "    per_device_train_batch_size=16,  # Reduced batch size for stability\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,   # Increased to maintain effective batch size\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_steps=500,                  \n",
    "    save_steps=500,                  \n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,  \n",
    "    processing_class=processor,  # Updated from tokenizer to processing_class\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a35d0",
   "metadata": {},
   "source": [
    "# Model Training Execution\n",
    "This cell initiates the fine-tuning process of the Whisper model on the Minangkabau language dataset using the configured trainer. The training will run for the specified number of epochs with periodic evaluation and checkpoint saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d8d2dd-e8be-4e2b-a5d4-c32fb9e3dce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:4037: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=5.78022829691569, metrics={'train_runtime': 59.0148, 'train_samples_per_second': 6.202, 'train_steps_per_second': 0.203, 'total_flos': 1.0562225651712e+17, 'train_loss': 5.78022829691569, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- STEP 5: Training üöÄ ---\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0faf4-d229-4b61-afeb-a8da43c3897c",
   "metadata": {},
   "source": [
    "# Model Testing and Evaluation\n",
    "This section loads the test dataset and evaluates the fine-tuned Whisper model's performance on unseen Minangkabau audio samples. It processes the test audio files and compares the model's transcriptions with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a870b2c-6294-4ef2-adf0-9913b381cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Extracting test audio files...\n",
      "‚úÖ Test audio extracted\n",
      "üìä Total test samples: 754\n",
      "üéØ Minangkabau test samples: 20\n",
      "\n",
      "üìù Sample test data:\n",
      "                                            sentence  \\\n",
      "0                       katahui bana hak hak awak ko   \n",
      "1  dan kabebasan dari raso takuik dan dari kakura...   \n",
      "2                           supayo manjadi kanyataan   \n",
      "\n",
      "                                                path  \n",
      "0  test/minangkabau/universal-declaration-of-huma...  \n",
      "1  test/minangkabau/universal-declaration-of-huma...  \n",
      "2  test/minangkabau/universal-declaration-of-huma...  \n"
     ]
    }
   ],
   "source": [
    "# --- Prepare Test Data ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "\n",
    "# Extract test audio if not already extracted\n",
    "test_archive = \"/workspace/data/audio_test.tgz\"\n",
    "if os.path.exists(test_archive):\n",
    "    print(\"üìÇ Extracting test audio files...\")\n",
    "    with tarfile.open(test_archive, \"r:gz\") as tar:\n",
    "        tar.extractall(path=\"/workspace/data/audio_train\")\n",
    "    print(\"‚úÖ Test audio extracted\")\n",
    "\n",
    "# Load test metadata\n",
    "test_metadata_path = \"/workspace/data/metadata_test.csv.gz\"\n",
    "test_df = pd.read_csv(test_metadata_path)\n",
    "\n",
    "# Filter for Minangkabau language only\n",
    "test_df_min = test_df[test_df[\"language\"] == \"min\"].reset_index(drop=True)\n",
    "print(f\"üìä Total test samples: {len(test_df)}\")\n",
    "print(f\"üéØ Minangkabau test samples: {len(test_df_min)}\")\n",
    "\n",
    "# Add full paths\n",
    "audio_base_path = \"/workspace/data/audio_train/librivox-indonesia\"\n",
    "test_df_min[\"full_path\"] = test_df_min[\"path\"].apply(lambda p: os.path.join(audio_base_path, p))\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nüìù Sample test data:\")\n",
    "print(test_df_min[[\"sentence\", \"path\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05d86f56-343a-43c4-bd84-f611c788b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test audio: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully converted 20 test audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Convert Test Audio to WAV (if needed) ---\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_test_audio_to_wav(df, output_base):\n",
    "    \"\"\"Convert test audio files to WAV format for consistency\"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    converted_paths = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Converting test audio\"):\n",
    "        rel_path = row[\"path\"]\n",
    "        src_path = os.path.join(audio_base_path, rel_path)\n",
    "        \n",
    "        # Skip if source doesn't exist\n",
    "        if not os.path.exists(src_path):\n",
    "            converted_paths.append(None)\n",
    "            continue\n",
    "            \n",
    "        # Create WAV output path\n",
    "        out_rel_path = os.path.splitext(rel_path)[0] + \".wav\"\n",
    "        out_path = os.path.join(output_base, out_rel_path)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        \n",
    "        # Skip if already converted\n",
    "        if os.path.exists(out_path):\n",
    "            converted_paths.append(os.path.relpath(out_path, audio_base_path))\n",
    "            continue\n",
    "            \n",
    "        # Convert to WAV\n",
    "        cmd = [\"ffmpeg\", \"-y\", \"-i\", src_path, \"-ac\", \"1\", \"-ar\", \"16000\", out_path]\n",
    "        result = subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            converted_paths.append(os.path.relpath(out_path, audio_base_path))\n",
    "        else:\n",
    "            converted_paths.append(None)\n",
    "    \n",
    "    return converted_paths\n",
    "\n",
    "# Convert test audio\n",
    "test_output_base = os.path.join(audio_base_path, \"converted_wav\")\n",
    "test_df_min[\"wav_path\"] = convert_test_audio_to_wav(test_df_min, test_output_base)\n",
    "test_df_min[\"wav_full_path\"] = test_df_min[\"wav_path\"].apply(\n",
    "    lambda p: os.path.join(audio_base_path, p) if p else None\n",
    ")\n",
    "\n",
    "# Remove rows where conversion failed\n",
    "test_df_clean = test_df_min.dropna(subset=[\"wav_full_path\"]).reset_index(drop=True)\n",
    "print(f\"‚úÖ Successfully converted {len(test_df_clean)} test audio files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27be7f42-0037-4563-a854-6f313b05a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Testing model on sample audio files...\n",
      "Processing 1/5: human_rights_un_min_sd_0009.wav\n",
      "  Ground Truth: katahui bana hak hak awak ko\n",
      "  Prediction:    ‡§ï‡§æ‡§§‡§æ hui banahak hak awak\n",
      "  ==================================================\n",
      "Processing 2/5: human_rights_un_min_sd_0016.wav\n",
      "  Ground Truth: dan kabebasan dari raso takuik dan dari kakurangan\n",
      "  Prediction:    dan kababasan dari raso takuik dan dari kakurangan\n",
      "  ==================================================\n",
      "Processing 3/5: human_rights_un_min_sd_0028.wav\n",
      "  Ground Truth: supayo manjadi kanyataan\n",
      "  Prediction:    supayo manjadi kanyataan\n",
      "  ==================================================\n",
      "Processing 4/5: human_rights_un_min_sd_0039.wav\n",
      "  Ground Truth: indak ado pambedaan   umpamonyo pambedaan ras\n",
      "  Prediction:    indak ado pambedaan umpamonyo pambedaan ras\n",
      "  ==================================================\n",
      "Processing 5/5: human_rights_un_min_sd_0044.wav\n",
      "  Ground Truth: indak diadokan pambedaan badasar kadudukan politik\n",
      "  Prediction:    indak diadokan pambedaan badasar kadudukan politik\n",
      "  ==================================================\n",
      "Processing 6/5: human_rights_un_min_sd_0046.wav\n",
      "  Ground Truth: baiak babantuak negara mardeka\n",
      "  Prediction:    baiyak babantuak nagara mardeka\n",
      "  ==================================================\n",
      "Processing 7/5: human_rights_un_min_sd_0047.wav\n",
      "  Ground Truth: wilayah wilayah parwalian  jajahan atau bantuak katarbatasan kadaulatan nan lain\n",
      "  Prediction:    wilayah wilayah par walian jajahan atau bantuak katar batasan kadawlatan nan lain\n",
      "  ==================================================\n",
      "Processing 8/5: human_rights_un_min_sd_0055.wav\n",
      "  Ground Truth: pasal tujuh sadonyo urang samo di hadapan hukum\n",
      "  Prediction:    pahasol tujuah sadoianyo urang samo dihadapan hukum\n",
      "  ==================================================\n",
      "Processing 9/5: human_rights_un_min_sd_0060.wav\n",
      "  Ground Truth: pasal sembilan indak surang pun buliah ditangkok  ditahan atau diasiangkan sacaro sawenang wenang\n",
      "  Prediction:    diakasal sambilan indak surang pun buliah ditangkok ditahan atau diasiangkan sacaro sawanangmanang\n",
      "  ==================================================\n",
      "Processing 10/5: human_rights_un_min_sd_0061.wav\n",
      "  Ground Truth: pasal sepuluh tiok urang punyo hak nan samo mandapek paradilan nan adil dan tabuka di pangadilan nan bebas dan tak mamihak\n",
      "  Prediction:    punyo hak nan samo mandapek paradilan nan adil dan tabuka dipangadilan nan bebas nan tak mamihak\n",
      "  ==================================================\n",
      "Processing 11/5: human_rights_un_min_sd_0066.wav\n",
      "  Ground Truth: nan bukan tamasuak palanggaran hukum nasional atau internasional katiko paristiwa itu tajadi\n",
      "  Prediction:    nan bukan tamasua palanggaran hukum nasional atau internasional katiko paristiwa itu tajadi\n",
      "  ==================================================\n",
      "Processing 12/5: human_rights_un_min_sd_0075.wav\n",
      "  Ground Truth: pasal empat belas tiok urang punyo hak mancari dan manikmati suaka di negara lain untuak malinduangi diri dari panganiayoan  di negaranyo\n",
      "  Prediction:    pahal pahalak punyo hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak\n",
      "  ==================================================\n",
      "Processing 13/5: human_rights_un_min_sd_0089.wav\n",
      "  Ground Truth: bahati nurani dan ba agamo  tamasuak hak batuka agamo atau kaparcayaan\n",
      "  Prediction:    bahaikan\n",
      "  ==================================================\n",
      "Processing 14/5: human_rights_un_min_sd_0100.wav\n",
      "  Ground Truth: tiok urang punyo hak mandapek kasampatan nan samo untuak diangkek dalam jabatan pamarintahan negaranyo\n",
      "  Prediction:    diakurang punyo hak mandapek kasampatan nan samo untuak diangkak dalam jabatan pamerintahan negara nyo\n",
      "  ==================================================\n",
      "Processing 15/5: human_rights_un_min_sd_0101.wav\n",
      "  Ground Truth: kandak rakyat musti manjadi landasan kakuasaan pamarintah\n",
      "  Prediction:    kanda kraket musti manjadi landesan kekuasaan pabarinta\n",
      "  ==================================================\n",
      "Processing 16/5: human_rights_un_min_sd_0105.wav\n",
      "  Ground Truth: tiok urang punyo hak mandapek jaminan sosial dan punyo hak pulo untuak talaksananyo hak hak ekonomi\n",
      "  Prediction:    jindu punyo hak punyo hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak\n",
      "  ==================================================\n",
      "Processing 17/5: human_rights_un_min_sd_0113.wav\n",
      "  Ground Truth: baitu pulo punyo hak mandapek linduangan katiko manganggur\n",
      "  Prediction:    baitu pulo punyo hak mandapek linduangan katiko mangangur\n",
      "  ==================================================\n",
      "Processing 18/5: human_rights_un_min_sd_0119.wav\n",
      "  Ground Truth: tamasuak pambatasan nan layak taradok jam karajo\n",
      "  Prediction:    mabakasal nan layak taradok jam karajo\n",
      "  ==================================================\n",
      "Processing 19/5: human_rights_un_min_sd_0131.wav\n",
      "  Ground Truth: pandidikan dasar musti diwajibkan\n",
      "  Prediction:    pandidikan desar musti diwajibkan\n",
      "  ==================================================\n",
      "Processing 20/5: human_rights_un_min_sd_0146.wav\n",
      "  Ground Truth: pasal dua puluh delapan tiok urang punyo hak mandapek katartiban sosial dan katartiban internasional untuak mawujudkan saluruah hak hak dan kabebasan sasuai jo deklarasi ko\n",
      "  Prediction:    ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑ\n",
      "  ==================================================\n",
      "\n",
      "‚úÖ Completed testing on 20 samples\n"
     ]
    }
   ],
   "source": [
    "# --- Test Model Inference ---\n",
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "\n",
    "def transcribe_audio(audio_path, model, processor):\n",
    "    \"\"\"Transcribe a single audio file using the fine-tuned model\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLING_RATE:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, SAMPLING_RATE)\n",
    "        waveform = waveform.mean(dim=0)  # Convert to mono\n",
    "        \n",
    "        # Process audio\n",
    "        inputs = processor(\n",
    "            audio=waveform.numpy(),\n",
    "            sampling_rate=SAMPLING_RATE,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move to GPU\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate transcription\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                inputs[\"input_features\"],\n",
    "                max_length=448,\n",
    "                num_beams=1,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        # Decode transcription\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test on a small sample first (5 files)\n",
    "test_sample = test_df_clean.head(20).copy()\n",
    "print(\"üé§ Testing model on sample audio files...\")\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "\n",
    "for idx, row in test_sample.iterrows():\n",
    "    print(f\"Processing {idx+1}/20: {os.path.basename(row['wav_full_path'])}\")\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = transcribe_audio(row[\"wav_full_path\"], model, processor)\n",
    "    ground_truth = row[\"sentence\"]\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    ground_truths.append(ground_truth)\n",
    "    \n",
    "    print(f\"  Ground Truth: {ground_truth}\")\n",
    "    print(f\"  Prediction:   {prediction}\")\n",
    "    print(\"  \" + \"=\"*50)\n",
    "\n",
    "print(f\"\\n‚úÖ Completed testing on {len(test_sample)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd068e33-0ff1-476e-b181-27eae9d7b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EVALUATION RESULTS:\n",
      "==================================================\n",
      "üìù Number of samples: 20\n",
      "üéØ Word Error Rate (WER): 4.8857 (488.57%)\n",
      "üî§ Character Error Rate (CER): 2.8723 (287.23%)\n",
      "‚úÖ Word Accuracy: -388.57%\n",
      "\n",
      "üìã DETAILED COMPARISON:\n",
      "==================================================\n",
      "Sample 1:\n",
      "  Ground Truth: katahui bana hak hak awak ko\n",
      "  Prediction:    ‡§ï‡§æ‡§§‡§æ hui banahak hak awak\n",
      "  WER: 0.6667, CER: 0.3214\n",
      "\n",
      "Sample 2:\n",
      "  Ground Truth: dan kabebasan dari raso takuik dan dari kakurangan\n",
      "  Prediction:    dan kababasan dari raso takuik dan dari kakurangan\n",
      "  WER: 0.1250, CER: 0.0200\n",
      "\n",
      "Sample 3:\n",
      "  Ground Truth: supayo manjadi kanyataan\n",
      "  Prediction:    supayo manjadi kanyataan\n",
      "  WER: 0.0000, CER: 0.0000\n",
      "\n",
      "Sample 4:\n",
      "  Ground Truth: indak ado pambedaan   umpamonyo pambedaan ras\n",
      "  Prediction:    indak ado pambedaan umpamonyo pambedaan ras\n",
      "  WER: 0.0000, CER: 0.0444\n",
      "\n",
      "Sample 5:\n",
      "  Ground Truth: indak diadokan pambedaan badasar kadudukan politik\n",
      "  Prediction:    indak diadokan pambedaan badasar kadudukan politik\n",
      "  WER: 0.0000, CER: 0.0000\n",
      "\n",
      "Sample 6:\n",
      "  Ground Truth: baiak babantuak negara mardeka\n",
      "  Prediction:    baiyak babantuak nagara mardeka\n",
      "  WER: 0.5000, CER: 0.0667\n",
      "\n",
      "Sample 7:\n",
      "  Ground Truth: wilayah wilayah parwalian  jajahan atau bantuak katarbatasan kadaulatan nan lain\n",
      "  Prediction:    wilayah wilayah par walian jajahan atau bantuak katar batasan kadawlatan nan lain\n",
      "  WER: 0.5000, CER: 0.0500\n",
      "\n",
      "Sample 8:\n",
      "  Ground Truth: pasal tujuh sadonyo urang samo di hadapan hukum\n",
      "  Prediction:    pahasol tujuah sadoianyo urang samo dihadapan hukum\n",
      "  WER: 0.6250, CER: 0.1489\n",
      "\n",
      "Sample 9:\n",
      "  Ground Truth: pasal sembilan indak surang pun buliah ditangkok  ditahan atau diasiangkan sacaro sawenang wenang\n",
      "  Prediction:    diakasal sambilan indak surang pun buliah ditangkok ditahan atau diasiangkan sacaro sawanangmanang\n",
      "  WER: 0.3077, CER: 0.1031\n",
      "\n",
      "Sample 10:\n",
      "  Ground Truth: pasal sepuluh tiok urang punyo hak nan samo mandapek paradilan nan adil dan tabuka di pangadilan nan bebas dan tak mamihak\n",
      "  Prediction:    punyo hak nan samo mandapek paradilan nan adil dan tabuka dipangadilan nan bebas nan tak mamihak\n",
      "  WER: 0.3333, CER: 0.2213\n",
      "\n",
      "Sample 11:\n",
      "  Ground Truth: nan bukan tamasuak palanggaran hukum nasional atau internasional katiko paristiwa itu tajadi\n",
      "  Prediction:    nan bukan tamasua palanggaran hukum nasional atau internasional katiko paristiwa itu tajadi\n",
      "  WER: 0.0833, CER: 0.0109\n",
      "\n",
      "Sample 12:\n",
      "  Ground Truth: pasal empat belas tiok urang punyo hak mancari dan manikmati suaka di negara lain untuak malinduangi diri dari panganiayoan  di negaranyo\n",
      "  Prediction:    pahal pahalak punyo hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak\n",
      "  WER: 20.8095, CER: 12.4307\n",
      "\n",
      "Sample 13:\n",
      "  Ground Truth: bahati nurani dan ba agamo  tamasuak hak batuka agamo atau kaparcayaan\n",
      "  Prediction:    bahaikan\n",
      "  WER: 1.0000, CER: 0.8857\n",
      "\n",
      "Sample 14:\n",
      "  Ground Truth: tiok urang punyo hak mandapek kasampatan nan samo untuak diangkek dalam jabatan pamarintahan negaranyo\n",
      "  Prediction:    diakurang punyo hak mandapek kasampatan nan samo untuak diangkak dalam jabatan pamerintahan negara nyo\n",
      "  WER: 0.4286, CER: 0.0588\n",
      "\n",
      "Sample 15:\n",
      "  Ground Truth: kandak rakyat musti manjadi landasan kakuasaan pamarintah\n",
      "  Prediction:    kanda kraket musti manjadi landesan kekuasaan pabarinta\n",
      "  WER: 0.7143, CER: 0.1404\n",
      "\n",
      "Sample 16:\n",
      "  Ground Truth: tiok urang punyo hak mandapek jaminan sosial dan punyo hak pulo untuak talaksananyo hak hak ekonomi\n",
      "  Prediction:    jindu punyo hak punyo hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak hak\n",
      "  WER: 27.1875, CER: 17.3333\n",
      "\n",
      "Sample 17:\n",
      "  Ground Truth: baitu pulo punyo hak mandapek linduangan katiko manganggur\n",
      "  Prediction:    baitu pulo punyo hak mandapek linduangan katiko mangangur\n",
      "  WER: 0.1250, CER: 0.0172\n",
      "\n",
      "Sample 18:\n",
      "  Ground Truth: tamasuak pambatasan nan layak taradok jam karajo\n",
      "  Prediction:    mabakasal nan layak taradok jam karajo\n",
      "  WER: 0.2857, CER: 0.2500\n",
      "\n",
      "Sample 19:\n",
      "  Ground Truth: pandidikan dasar musti diwajibkan\n",
      "  Prediction:    pandidikan desar musti diwajibkan\n",
      "  WER: 0.2500, CER: 0.0303\n",
      "\n",
      "Sample 20:\n",
      "  Ground Truth: pasal dua puluh delapan tiok urang punyo hak mandapek katartiban sosial dan katartiban internasional untuak mawujudkan saluruah hak hak dan kabebasan sasuai jo deklarasi ko\n",
      "  Prediction:    ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑÿ™ ŸÖÿ≠ÿ®Ÿàÿ®ÿ© ŸàŸÇŸÑ\n",
      "  WER: 3.9600, CER: 3.2965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Evaluation Metrics ---\n",
    "try:\n",
    "    import jiwer\n",
    "    \n",
    "    # Filter out None predictions\n",
    "    valid_pairs = [(pred, gt) for pred, gt in zip(predictions, ground_truths) if pred is not None]\n",
    "    \n",
    "    if valid_pairs:\n",
    "        valid_predictions, valid_ground_truths = zip(*valid_pairs)\n",
    "        \n",
    "        # Convert tuples to lists for jiwer\n",
    "        valid_predictions = list(valid_predictions)\n",
    "        valid_ground_truths = list(valid_ground_truths)\n",
    "        \n",
    "        # Calculate Word Error Rate (WER)\n",
    "        wer_score = jiwer.wer(valid_ground_truths, valid_predictions)\n",
    "        \n",
    "        # Calculate Character Error Rate (CER)\n",
    "        cer_score = jiwer.cer(valid_ground_truths, valid_predictions)\n",
    "        \n",
    "        print(\"üìä EVALUATION RESULTS:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üìù Number of samples: {len(valid_pairs)}\")\n",
    "        print(f\"üéØ Word Error Rate (WER): {wer_score:.4f} ({wer_score*100:.2f}%)\")\n",
    "        print(f\"üî§ Character Error Rate (CER): {cer_score:.4f} ({cer_score*100:.2f}%)\")\n",
    "        print(f\"‚úÖ Word Accuracy: {(1-wer_score)*100:.2f}%\")\n",
    "        \n",
    "        # Show detailed comparison\n",
    "        print(f\"\\nüìã DETAILED COMPARISON:\")\n",
    "        print(\"=\"*50)\n",
    "        for i, (pred, gt) in enumerate(valid_pairs):\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Ground Truth: {gt}\")\n",
    "            print(f\"  Prediction:   {pred}\")\n",
    "            \n",
    "            # Calculate individual metrics\n",
    "            individual_wer = jiwer.wer([gt], [pred])\n",
    "            individual_cer = jiwer.cer([gt], [pred])\n",
    "            print(f\"  WER: {individual_wer:.4f}, CER: {individual_cer:.4f}\")\n",
    "            print()\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå No valid predictions to evaluate\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è jiwer not available. Install with: pip install jiwer\")\n",
    "    print(\"Showing basic comparison instead...\")\n",
    "    \n",
    "    for i, (pred, gt) in enumerate(zip(predictions, ground_truths)):\n",
    "        if pred is not None:\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Ground Truth: {gt}\")\n",
    "            print(f\"  Prediction:   {pred}\")\n",
    "            print(f\"  Match: {'‚úÖ' if pred.lower().strip() == gt.lower().strip() else '‚ùå'}\")\n",
    "            print()\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error calculating metrics: {e}\")\n",
    "    print(\"Showing basic comparison instead...\")\n",
    "    \n",
    "    for i, (pred, gt) in enumerate(zip(predictions, ground_truths)):\n",
    "        if pred is not None:\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Ground Truth: {gt}\")\n",
    "            print(f\"  Prediction:   {pred}\")\n",
    "            print(f\"  Match: {'‚úÖ' if pred.lower().strip() == gt.lower().strip() else '‚ùå'}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0df38a30-4334-4941-9a92-96ff6a646669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Re-testing model with improved generation parameters...\n",
      "Processing 1/5: human_rights_un_min_sd_0009.wav\n",
      "  Ground Truth: katahui bana hak hak awak ko\n",
      "  Prediction:   upadamahek punyal hak takua diketuikan jo\n",
      "  ==================================================\n",
      "Processing 2/5: human_rights_un_min_sd_0016.wav\n",
      "  Ground Truth: dan kabebasan dari raso takuik dan dari kakurangan\n",
      "  Prediction:   dan kamabasani da di raso tak kakui nan dari kaku\n",
      "  ==================================================\n",
      "Processing 3/5: human_rights_un_min_sd_0028.wav\n",
      "  Ground Truth: supayo manjadi kanyataan\n",
      "  Prediction:   supayao manzadikan yataan\n",
      "  ==================================================\n",
      "Processing 4/5: human_rights_un_min_sd_0039.wav\n",
      "  Ground Truth: indak ado pambedaan   umpamonyo pambedaan ras\n",
      "  Prediction:   indak ado pangbedaan unpamonyo pampedakan rasia\n",
      "  ==================================================\n",
      "Processing 5/5: human_rights_un_min_sd_0044.wav\n",
      "  Ground Truth: indak diadokan pambedaan badasar kadudukan politik\n",
      "  Prediction:   indak diredokan pembedaan bada sar kadudukan politiku tuan dikambahai urang dan cinta\n",
      "  ==================================================\n",
      "\n",
      "‚úÖ Completed improved testing on 5 samples\n"
     ]
    }
   ],
   "source": [
    "# --- Improved Model Testing with Better Generation Parameters ---\n",
    "def transcribe_audio_improved(audio_path, model, processor):\n",
    "    \"\"\"Transcribe with improved generation parameters to avoid repetition\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if sr != SAMPLING_RATE:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, SAMPLING_RATE)\n",
    "        waveform = waveform.mean(dim=0)  # Convert to mono\n",
    "        \n",
    "        # Process audio\n",
    "        inputs = processor(\n",
    "            audio=waveform.numpy(),\n",
    "            sampling_rate=SAMPLING_RATE,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move to GPU\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate transcription with improved parameters\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                inputs[\"input_features\"],\n",
    "                max_length=200,  # Reduced from 448\n",
    "                min_length=1,\n",
    "                num_beams=3,     # Increased from 1\n",
    "                do_sample=False,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,  # Prevent repetition\n",
    "                repetition_penalty=1.2,   # Penalize repetition\n",
    "                length_penalty=1.0,\n",
    "                bad_words_ids=[[50257]],  # Avoid problematic tokens\n",
    "                forced_decoder_ids=None,\n",
    "                temperature=1.0\n",
    "            )\n",
    "        \n",
    "        # Decode transcription\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return transcription.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with improved parameters on first 5 samples only\n",
    "test_sample_improved = test_df_clean.head(5).copy()\n",
    "print(\"üé§ Re-testing model with improved generation parameters...\")\n",
    "\n",
    "improved_predictions = []\n",
    "improved_ground_truths = []\n",
    "\n",
    "for idx, row in test_sample_improved.iterrows():\n",
    "    print(f\"Processing {idx+1}/5: {os.path.basename(row['wav_full_path'])}\")\n",
    "    \n",
    "    # Get prediction with improved parameters\n",
    "    prediction = transcribe_audio_improved(row[\"wav_full_path\"], model, processor)\n",
    "    ground_truth = row[\"sentence\"]\n",
    "    \n",
    "    improved_predictions.append(prediction)\n",
    "    improved_ground_truths.append(ground_truth)\n",
    "    \n",
    "    print(f\"  Ground Truth: {ground_truth}\")\n",
    "    print(f\"  Prediction:   {prediction}\")\n",
    "    print(\"  \" + \"=\"*50)\n",
    "\n",
    "print(f\"\\n‚úÖ Completed improved testing on {len(test_sample_improved)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c93cb333-a7bf-49a5-a3ce-e2ab9c0d7c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä IMPROVED EVALUATION RESULTS:\n",
      "============================================================\n",
      "üìù Number of valid samples: 5\n",
      "üéØ Word Error Rate (WER): 1.0000 (100.00%)\n",
      "üî§ Character Error Rate (CER): 0.4619 (46.19%)\n",
      "‚úÖ Word Accuracy: 0.00%\n",
      "üìà Character Accuracy: 53.81%\n",
      "\n",
      "üìã DETAILED COMPARISON (IMPROVED):\n",
      "============================================================\n",
      "Sample 1:\n",
      "  Ground Truth: katahui bana hak hak awak ko\n",
      "  Prediction:   upadamahek punyal hak takua diketuikan jo\n",
      "  üìä WER: 0.8333, CER: 0.8571\n",
      "  ‚ùå Needs improvement\n",
      "\n",
      "Sample 2:\n",
      "  Ground Truth: dan kabebasan dari raso takuik dan dari kakurangan\n",
      "  Prediction:   dan kamabasani da di raso tak kakui nan dari kaku\n",
      "  üìä WER: 0.8750, CER: 0.3400\n",
      "  ‚ùå Needs improvement\n",
      "\n",
      "Sample 3:\n",
      "  Ground Truth: supayo manjadi kanyataan\n",
      "  Prediction:   supayao manzadikan yataan\n",
      "  üìä WER: 1.0000, CER: 0.1667\n",
      "  ‚ùå Needs improvement\n",
      "\n",
      "Sample 4:\n",
      "  Ground Truth: indak ado pambedaan   umpamonyo pambedaan ras\n",
      "  Prediction:   indak ado pangbedaan unpamonyo pampedakan rasia\n",
      "  üìä WER: 0.6667, CER: 0.2000\n",
      "  ‚ùå Needs improvement\n",
      "\n",
      "Sample 5:\n",
      "  Ground Truth: indak diadokan pambedaan badasar kadudukan politik\n",
      "  Prediction:   indak diredokan pembedaan bada sar kadudukan politiku tuan dikambahai urang dan cinta\n",
      "  üìä WER: 1.6667, CER: 0.7400\n",
      "  ‚ùå Needs improvement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Improved Evaluation Metrics ---\n",
    "try:\n",
    "    import jiwer\n",
    "    \n",
    "    # Filter out None predictions from improved results\n",
    "    valid_pairs_improved = [(pred, gt) for pred, gt in zip(improved_predictions, improved_ground_truths) if pred is not None and pred.strip() != \"\"]\n",
    "    \n",
    "    if valid_pairs_improved:\n",
    "        valid_predictions_improved, valid_ground_truths_improved = zip(*valid_pairs_improved)\n",
    "        \n",
    "        # Convert tuples to lists for jiwer\n",
    "        valid_predictions_improved = list(valid_predictions_improved)\n",
    "        valid_ground_truths_improved = list(valid_ground_truths_improved)\n",
    "        \n",
    "        # Calculate Word Error Rate (WER)\n",
    "        wer_score_improved = jiwer.wer(valid_ground_truths_improved, valid_predictions_improved)\n",
    "        \n",
    "        # Calculate Character Error Rate (CER)\n",
    "        cer_score_improved = jiwer.cer(valid_ground_truths_improved, valid_predictions_improved)\n",
    "        \n",
    "        print(\"üìä IMPROVED EVALUATION RESULTS:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìù Number of valid samples: {len(valid_pairs_improved)}\")\n",
    "        print(f\"üéØ Word Error Rate (WER): {wer_score_improved:.4f} ({wer_score_improved*100:.2f}%)\")\n",
    "        print(f\"üî§ Character Error Rate (CER): {cer_score_improved:.4f} ({cer_score_improved*100:.2f}%)\")\n",
    "        print(f\"‚úÖ Word Accuracy: {(1-wer_score_improved)*100:.2f}%\")\n",
    "        print(f\"üìà Character Accuracy: {(1-cer_score_improved)*100:.2f}%\")\n",
    "        \n",
    "        # Show detailed comparison\n",
    "        print(f\"\\nüìã DETAILED COMPARISON (IMPROVED):\")\n",
    "        print(\"=\"*60)\n",
    "        for i, (pred, gt) in enumerate(valid_pairs_improved):\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Ground Truth: {gt}\")\n",
    "            print(f\"  Prediction:   {pred}\")\n",
    "            \n",
    "            # Calculate individual metrics\n",
    "            individual_wer = jiwer.wer([gt], [pred])\n",
    "            individual_cer = jiwer.cer([gt], [pred])\n",
    "            print(f\"  üìä WER: {individual_wer:.4f}, CER: {individual_cer:.4f}\")\n",
    "            \n",
    "            # Show if it's a good prediction\n",
    "            if individual_wer < 0.3:\n",
    "                print(f\"  ‚úÖ Good transcription!\")\n",
    "            elif individual_wer < 0.6:\n",
    "                print(f\"  ‚ö†Ô∏è Moderate accuracy\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Needs improvement\")\n",
    "            print()\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå No valid predictions to evaluate in improved results\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error calculating improved metrics: {e}\")\n",
    "    print(\"Showing basic comparison instead...\")\n",
    "    \n",
    "    for i, (pred, gt) in enumerate(zip(improved_predictions, improved_ground_truths)):\n",
    "        if pred is not None and pred.strip() != \"\":\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Ground Truth: {gt}\")\n",
    "            print(f\"  Prediction:   {pred}\")\n",
    "            print(f\"  Match: {'‚úÖ' if pred.lower().strip() == gt.lower().strip() else '‚ùå'}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b055734-24fb-4883-8633-3ada0ca318e7",
   "metadata": {},
   "source": [
    "# Model Analysis and Improvement Suggestions\n",
    "This section analyzes the model performance and provides insights into potential improvements. The results show that while the model has learned some Minangkabau patterns, it needs more training or different hyperparameters to achieve better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c769168e-0b4b-4ee2-a18b-be18165ebaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PERFORMANCE ANALYSIS:\n",
      "============================================================\n",
      "\n",
      "üìä Current Model Performance:\n",
      "   ‚Ä¢ Word Error Rate: 100.0%\n",
      "   ‚Ä¢ Character Error Rate: 46.2%\n",
      "   ‚Ä¢ Word Accuracy: 0.0%\n",
      "   ‚Ä¢ Character Accuracy: 53.8%\n",
      "\n",
      "üéØ Accuracy Interpretation:\n",
      "   ‚ùå High WER (>80%): Model needs significant improvement\n",
      "\n",
      "üî§ Character-level Analysis:\n",
      "   üî∂ Moderate character accuracy - some phonetic understanding\n",
      "\n",
      "üìà Training Insights:\n",
      "   ‚Ä¢ Short training (3 epochs, 12 steps) - likely underfitted\n",
      "   ‚Ä¢ Model shows some Minangkabau patterns but needs more exposure\n",
      "   ‚Ä¢ Character-level performance better than word-level suggests partial learning\n",
      "\n",
      "üõ†Ô∏è Improvement Strategies:\n",
      "   1. Increase training epochs (5-10 epochs)\n",
      "   2. Lower learning rate for fine-grained learning\n",
      "   3. Increase dataset size if possible\n",
      "   4. Use data augmentation (speed/pitch variations)\n",
      "   5. Fine-tune generation parameters further\n",
      "   6. Consider using Whisper-base instead of small for better capacity\n"
     ]
    }
   ],
   "source": [
    "# --- Performance Analysis ---\n",
    "print(\"üîç PERFORMANCE ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate basic statistics from the improved results\n",
    "if 'valid_pairs_improved' in locals() and valid_pairs_improved:\n",
    "    print(f\"\\nüìä Current Model Performance:\")\n",
    "    print(f\"   ‚Ä¢ Word Error Rate: {wer_score_improved*100:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Character Error Rate: {cer_score_improved*100:.1f}%\") \n",
    "    print(f\"   ‚Ä¢ Word Accuracy: {(1-wer_score_improved)*100:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Character Accuracy: {(1-cer_score_improved)*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüéØ Accuracy Interpretation:\")\n",
    "    if wer_score_improved > 0.8:\n",
    "        print(\"   ‚ùå High WER (>80%): Model needs significant improvement\")\n",
    "    elif wer_score_improved > 0.5:\n",
    "        print(\"   ‚ö†Ô∏è Moderate WER (50-80%): Model shows some learning but needs refinement\")\n",
    "    elif wer_score_improved > 0.3:\n",
    "        print(\"   üî∂ Fair WER (30-50%): Model is learning patterns well\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Good WER (<30%): Model performing well\")\n",
    "        \n",
    "    print(f\"\\nüî§ Character-level Analysis:\")\n",
    "    if cer_score_improved < 0.3:\n",
    "        print(\"   ‚úÖ Good character accuracy - model understands phonetics\")\n",
    "    elif cer_score_improved < 0.6:\n",
    "        print(\"   üî∂ Moderate character accuracy - some phonetic understanding\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Poor character accuracy - limited phonetic learning\")\n",
    "\n",
    "print(f\"\\nüìà Training Insights:\")\n",
    "print(\"   ‚Ä¢ Short training (3 epochs, 12 steps) - likely underfitted\")\n",
    "print(\"   ‚Ä¢ Model shows some Minangkabau patterns but needs more exposure\")\n",
    "print(\"   ‚Ä¢ Character-level performance better than word-level suggests partial learning\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è Improvement Strategies:\")\n",
    "print(\"   1. Increase training epochs (5-10 epochs)\")\n",
    "print(\"   2. Lower learning rate for fine-grained learning\")\n",
    "print(\"   3. Increase dataset size if possible\")\n",
    "print(\"   4. Use data augmentation (speed/pitch variations)\")\n",
    "print(\"   5. Fine-tune generation parameters further\")\n",
    "print(\"   6. Consider using Whisper-base instead of small for better capacity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba259405-820b-4c19-9516-7a4309455b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING FINE-TUNED MODEL:\n",
      "==================================================\n",
      "Saving model to: ./whisper-minang-final\n",
      "‚úÖ Model and processor saved successfully!\n",
      "üìÅ Location: ./whisper-minang-final\n",
      "üìä Training results summary saved!\n",
      "\n",
      "üîÑ To load this model later, use:\n",
      "```python\n",
      "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
      "processor = WhisperProcessor.from_pretrained('./whisper-minang-final')\n",
      "model = WhisperForConditionalGeneration.from_pretrained('./whisper-minang-final')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# --- Save Model for Future Use ---\n",
    "print(\"üíæ SAVING FINE-TUNED MODEL:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Save the fine-tuned model and processor\n",
    "    model_save_path = \"./whisper-minang-final\"\n",
    "    \n",
    "    print(f\"Saving model to: {model_save_path}\")\n",
    "    model.save_pretrained(model_save_path)\n",
    "    processor.save_pretrained(model_save_path)\n",
    "    \n",
    "    print(\"‚úÖ Model and processor saved successfully!\")\n",
    "    print(f\"üìÅ Location: {model_save_path}\")\n",
    "    \n",
    "    # Save a summary of the training results\n",
    "    results_summary = {\n",
    "        \"model_name\": \"whisper-small-minangkabau\",\n",
    "        \"training_epochs\": 3,\n",
    "        \"training_steps\": 12,\n",
    "        \"final_loss\": 5.78,\n",
    "        \"test_samples\": len(valid_pairs_improved) if 'valid_pairs_improved' in locals() else 0,\n",
    "        \"word_error_rate\": f\"{wer_score_improved*100:.2f}%\" if 'wer_score_improved' in locals() else \"N/A\",\n",
    "        \"character_error_rate\": f\"{cer_score_improved*100:.2f}%\" if 'cer_score_improved' in locals() else \"N/A\",\n",
    "        \"word_accuracy\": f\"{(1-wer_score_improved)*100:.2f}%\" if 'wer_score_improved' in locals() else \"N/A\",\n",
    "        \"character_accuracy\": f\"{(1-cer_score_improved)*100:.2f}%\" if 'cer_score_improved' in locals() else \"N/A\"\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(f\"{model_save_path}/training_results.json\", \"w\") as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "    print(\"üìä Training results summary saved!\")\n",
    "    \n",
    "    # Instructions for loading the model later\n",
    "    print(f\"\\nüîÑ To load this model later, use:\")\n",
    "    print(f\"```python\")\n",
    "    print(f\"from transformers import WhisperProcessor, WhisperForConditionalGeneration\")\n",
    "    print(f\"processor = WhisperProcessor.from_pretrained('{model_save_path}')\")\n",
    "    print(f\"model = WhisperForConditionalGeneration.from_pretrained('{model_save_path}')\")\n",
    "    print(f\"```\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving model: {e}\")\n",
    "    print(\"The model is still available in memory for this session.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
